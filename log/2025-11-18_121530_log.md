# 2025-11-18 12:15:30 自動掃描與修改紀錄

- 作者: GitHub Copilot (自動操作)
- 事件: 掃描整個專案 Python 檔案語法，並記錄與 commit 變更。
- 受影響檔案（本次變更）:
  - `video_pipeline/config.py` (先前變更：移除 os.getenv, 改用 Optional, env_file 絕對路徑)
  - `video_pipeline/main.py` (加入中英雙語說明、注解、與 rewrite 健全性檢查)
  - `CHANGE_LOG_README.md` (新增 log 行號規範說明)
  - `log/2025-11-18_120000_log.md` (先前新增，並已加入 config.py 修改後內容)

- 本次掃描結果摘要:
  - 我已使用 Pylance 語法檢查逐一檢查所有 Python 檔案，結果：沒有發現語法錯誤 (No syntax errors found) 。
  - 因為先前已對 `config.py` 與 `main.py` 做過修正，這些檔案現已無語法錯誤。

- 修改後檔案快照（包含 `main.py` 完整內容，附行號）:

```py
 1: """
 2: AI Video Production Pipeline API
 3: 
 4: 檔案說明（File description）:
 5:     - 本檔為整個 AI 影片製作流程的 API 入口。
 6:     - 流程範例：video -> transcription -> rewrite -> image generation -> video generation -> TTS -> music -> assembly
 7:     - 此檔提供 HTTP endpoint 以啟動與查詢 pipeline 作業（在簡易範例中 job 狀態儲存在記憶體）
 8: 
 9: File description (English):
10:     - This module exposes FastAPI endpoints to start and monitor an AI video production pipeline.
11:     - Typical pipeline: video -> transcript -> script rewrite -> image generation -> video generation -> TTS -> music -> final assembly
12:     - Jobs are stored in an in-memory dict for simplicity; production should use Redis/DB for persistence.
13: 
14: 注意 / Notes:
15:     - Imports like `from services...` assume this module runs with the project root on `PYTHONPATH`.
16:       If you run via `python -m video_pipeline.main` or with a proper package entry, imports should resolve.
17:     - 目前以 in-memory `jobs` 儲存狀態；多人或多程序部署時請改用共享儲存（Redis/DB）。
18: """
19: 
20: from fastapi import FastAPI, File, UploadFile, BackgroundTasks, HTTPException
21: from fastapi.responses import JSONResponse
22: from pydantic import BaseModel
23: from typing import List, Optional, Dict, Any
24: import os
25: import json
26: import asyncio
27: from datetime import datetime
28: from pathlib import Path
29: 
30: # 假設其他模塊已寫好（下面會提供）
31: from config import settings
32: from models import *
33: from services.video_processor import VideoProcessor
34: from services.transcription import TranscriptionService
35: from services.syllable_counter import SyllableCounter
36: from services.frame_extractor import FrameExtractor
37: from services.qwen_service import QwenService
38: from services.chatgpt_service import ChatGPTService
39: from services.image_gen import ImageGenService
40: from services.video_gen import VideoGenService
41: from services.tts_service import TTSService
42: from services.music_service import MusicService
43: from services.video_assembly import VideoAssembler
44: from utils.file_manager import FileManager
45: from utils.retry_handler import retry_with_limit
46: 
47: app = FastAPI(title="AI Video Pipeline", version="1.0.0")
48: 
49: # 全局 job 狀態（生產環境用 Redis/DB）
50: jobs: Dict[str, Dict[str, Any]] = {}
51: 
52: 
53: @app.post("/api/pipeline/start")
54: async def start_pipeline(
55:     background_tasks: BackgroundTasks,
56:     file: UploadFile = File(...),
57:     title: Optional[str] = None
58: ):
59:     """
60:     啟動完整 pipeline
61:     Start the full pipeline
62:     """
63:     job_id = datetime.now().strftime("%Y%m%d_%H%M%S")
64:     
65:     # 儲存上傳檔案
66:     upload_path = Path(settings.UPLOAD_DIR) / job_id
67:     upload_path.mkdir(parents=True, exist_ok=True)
68:     video_path = upload_path / file.filename
69:     
70:     with open(video_path, "wb") as f:
71:         content = await file.read()
72:         f.write(content)
73:     
74:     # 注意：此處將整個上傳檔讀入記憶體，對大檔案可能會造成記憶體壓力。
75:     # Note: reading the whole uploaded file into memory may cause high memory usage for large files.
76:     
77:     # 初始化 job 狀態
78:     jobs[job_id] = {
79:         "status": "started",
80:         "video_path": str(video_path),
81:         "title": title or f"video_{job_id}",
82:         "current_step": "uploading",
83:         "progress": 0,
84:         "errors": [],
85:         "warnings": []
86:     }
87:     
88:     # 背景執行
89:     # BackgroundTasks 可以接受 coroutine function；FastAPI/Starlette 會將其排程執行。
90:     # BackgroundTasks accepts coroutine functions; Starlette will schedule them on the event loop.
91:     background_tasks.add_task(run_pipeline, job_id, str(video_path), title)
92:     
93:     return {"job_id": job_id, "message": "Pipeline started"}
94: 
95: 
96: @app.get("/api/pipeline/status/{job_id}")
97: async def get_status(job_id: str):
98:     """查詢 job 狀態 / Get job status"""
99:     if job_id not in jobs:
100:         raise HTTPException(status_code=404, detail="Job not found")
101:     return jobs[job_id]
102: 
103: 
104: async def run_pipeline(job_id: str, video_path: str, title: str):
105:     """
106:     主 pipeline 流程 / Main pipeline flow
107:     """
108:     # NOTE: Each service used below (VideoProcessor, TranscriptionService, etc.)
109:     # should implement appropriate error handling and timeouts.
110:     # 如果希望更細緻的錯誤回復/重試策略，可在各服務或此處加入 retry 機制。
111:     try:
112:         # 1. 影片預處理
113:         jobs[job_id]["current_step"] = "video_processing"
114:         jobs[job_id]["progress"] = 5
115:         
116:         processor = VideoProcessor()
117:         video_meta = await processor.extract_metadata(video_path)
118:         audio_path = await processor.extract_audio(video_path)
119:         
120:         jobs[job_id]["video_meta"] = video_meta
121:         jobs[job_id]["audio_path"] = audio_path
122:         
123:         # 2. 語音轉文字
124:         jobs[job_id]["current_step"] = "transcription"
124:         jobs[job_id]["progress"] = 15
125: 
126:         transcriber = TranscriptionService()
127:         transcript = await transcriber.transcribe(audio_path)
128:         
129:         jobs[job_id]["transcript"] = transcript
130: 
131:         # 3. 計算發音數
132:         jobs[job_id]["current_step"] = "syllable_counting"
133:         jobs[job_id]["progress"] = 20
134: 
135:         counter = SyllableCounter()
136:         new_syllable_data
136:         syllable_data = counter.count_all(transcript, video_meta["duration"])
137: 
138:         jobs[job_id]["syllable_data"] = syllable_data
139: 
140:         # 4. ChatGPT 改寫 script
141:         jobs[job_id]["current_step"] = "script_rewriting"
142:         jobs[job_id]["progress"] = 25
143: 
144:         chatgpt = ChatGPTService()
145:         new_script = await rewrite_script_with_retry(
146:             chatgpt, transcript, syllable_data, video_meta["duration"], job_id
147:         )
148: 
149:         jobs[job_id]["new_script"] = new_script
150: 
151:         # 5. 抽 frame
152:         jobs[job_id]["current_step"] = "frame_extraction"
153:         jobs[job_id]["progress"] = 35
154: 
155:         extractor = FrameExtractor()
156:         frames_data = await extractor.extract_frames_per_sentence(
157:             video_path, transcript, video_meta["fps"], job_id, title
158:         )
159: 
160:         # 6. Qwen-VL3 反推
161:         jobs[job_id]["current_step"] = "qwen_analysis"
162:         jobs[job_id]["progress"] = 45
163: 
164:         qwen = QwenService()
165:         analyzed_frames = await qwen.analyze_frames(frames_data)
166: 
167:         # 7. 統一風格 + 生成 prompts
168:         jobs[job_id]["current_step"] = "style_unification"
169:         jobs[job_id]["progress"] = 55
170: 
171:         unified_data = await chatgpt.unify_style_and_prompts(
172:             analyzed_frames, new_script, syllable_data
173:         )
174: 
175:         jobs[job_id]["unified_data"] = unified_data
176: 
177:         # 8. 文生圖
178:         jobs[job_id]["current_step"] = "image_generation"
179:         jobs[job_id]["progress"] = 65
180: 
181:         image_gen = ImageGenService()
182:         images_result = await generate_images_with_safety(
183:             image_gen, qwen, chatgpt, unified_data, job_id, title
184:         )
185: 
186:         # 9. 圖生影片
187:         jobs[job_id]["current_step"] = "video_generation"
188:         jobs[job_id]["progress"] = 75
189: 
190:         video_gen = VideoGenService()
191:         clips = await video_gen.generate_clips(images_result, job_id, title)
192: 
193:         # 10. TTS
194:         jobs[job_id]["current_step"] = "tts_generation"
195:         jobs[job_id]["progress"] = 85
196: 
197:         tts = TTSService()
198:         dialogue_audio = await tts.generate_dialogue(new_script, job_id, title)
199: 
200:         # 11. 音樂
201:         jobs[job_id]["current_step"] = "music_generation"
202:         jobs[job_id]["progress"] = 90
203: 
204:         music_service = MusicService()
205:         music_path = await music_service.generate_and_cut_music(
206:             unified_data["summary"], dialogue_audio["duration"], job_id, title
207:         )
208: 
209:         # 12. 最終組裝
210:         jobs[job_id]["current_step"] = "final_assembly"
211:         jobs[job_id]["progress"] = 95
212: 
213:         assembler = VideoAssembler()
214:         final_video = await assembler.assemble(
215:             clips=clips,
216:             dialogue=dialogue_audio,
217:             music=music_path,
218:             srt_data=new_script,
219:             job_id=job_id,
220:             title=title
221:         )
222: 
223:         # 完成
224:         jobs[job_id]["status"] = "completed"
225:         jobs[job_id]["progress"] = 100
226:         jobs[job_id]["final_video"] = final_video
227: 
228:     except Exception as e:
229:         jobs[job_id]["status"] = "failed"
230:         jobs[job_id]["errors"].append(str(e))
231:         print(f"Pipeline failed: {e}")
232: 
233: 
234: async def rewrite_script_with_retry(
235:     chatgpt: ChatGPTService,
236:     transcript: List[dict],
237:     syllable_data: dict,
238:     duration: float,
239:     job_id: str,
240:     max_attempts: int = 10
241: ) -> List[dict]:
242:     """
243:     改寫 script 並檢查發音數，最多重試 10 次
244:     """
245:     # 健全性檢查：避免除以零（duration 或 target_sps 為 0）
246:     counter = SyllableCounter()
247:     target_sps = syllable_data.get("syllables_per_sec", 0)
248:     duration_safe = duration if (duration and duration > 0) else 1e-6
249: 
250:     for attempt in range(max_attempts):
251:         new_script = await chatgpt.rewrite_script(transcript, syllable_data)
252: 
253:         # 計算新 script 發音數
254:         new_syllables = counter.count_script(new_script)
255:         new_sps = new_syllables / duration_safe
256: 
257:         # 如果 target_sps 為 0，無法以相對比例比較，改採絕對判斷（若雙方皆為 0 則視為通過）
258:         if target_sps == 0:
259:             if new_syllables == 0:
260:                 return new_script
261:             else:
262:                 diff_pct = float("inf")
263:         else:
264:             diff_pct = abs(new_sps - target_sps) / target_sps
265: 
266:         if diff_pct <= 0.1:  # 差異 <= 10%
267:             return new_script
268: 
269:         # 差太多，要求調整
270:         feedback = f"發音數差 {diff_pct*100:.1f}%，目標 {target_sps:.2f}/s，你給 {new_sps:.2f}/s"
271:         jobs[job_id]["warnings"].append(f"Attempt {attempt+1}: {feedback}")
272:     
273:     # 超過 10 次
274:     jobs[job_id]["warnings"].append("⚠️ 發音數調整失敗，需人工處理")
275:     return new_script  # 返回最後一次結果
276: 
277: 
278: async def generate_images_with_safety(
279:     image_gen: ImageGenService,
280:     qwen: QwenService,
281:     chatgpt: ChatGPTService,
282:     unified_data: dict,
283:     job_id: str,
284:     title: str,
285:     max_retries: int = 3
286: ) -> dict:
287:     """
288:     生成圖片 + 安全檢查，最多重試 3 次
289:     """
290:     results = {"ok": [], "bad": []}
291:     
292:     for sentence in unified_data["per_sentence"]:
293:         for clip in sentence["clips"]:
294:             clip_id = clip["clip_id"]
295:             prompt = clip["prompt"]
296:             
297:             attempt = 0
298:             success = False
299:             
300:             while attempt < max_retries and not success:
301:                 # 生圖
302:                 img_path = await image_gen.generate(prompt, job_id, title, clip_id)
303:                 
304:                 # Qwen 安全檢查
305:                 safety_result = await qwen.check_safety(img_path)
306:                 
307:                 # ChatGPT 二次判斷
308:                 gpt_check = await chatgpt.verify_image_quality(
309:                     safety_result, prompt
310:                 )
311:                 
312:                 if gpt_check["status"] == "ok":
313:                     results["ok"].append({
314:                         "clip_id": clip_id,
315:                         "img_path": img_path,
316:                         "prompt": prompt
317:                     })
318:                     success = True
319:                 else:
320:                     attempt += 1
321:                     if attempt >= max_retries:
322:                         # 放入 bad
323:                         bad_path = FileManager.move_to_bad(img_path, job_id, title)
324:                         results["bad"].append({
325:                             "clip_id": clip_id,
326:                             "img_path": bad_path,
327:                             "reason": gpt_check["reason"]
328:                         })
329:                         jobs[job_id]["warnings"].append(
330:                             f"⚠️ {clip_id} 生圖失敗 3 次，需人工處理"
331:                         )
332:     
333:     return results
334: 
335: 
336: if __name__ == "__main__":
337:     import uvicorn
338:     uvicorn.run(app, host="0.0.0.0", port=8000)
```

- 備註:
  - 我已把本次動作記錄於上方 log 檔，並準備將變更 commit 到 git（如下）。

(自動產生日誌)
